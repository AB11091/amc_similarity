{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from IPython.display import display, Latex\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Enable headless mode\n",
    "# headless mode should prevent the program from actually launching the ghost browser\n",
    "# saves time because I only need to visit the site to get the text\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "url = 'https://artofproblemsolving.com/wiki/index.php/2023_AMC_12B_Problems/Problem_6'\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       " When the roots of the polynomial \\[P(x)  = (x-1)^1 (x-2)^2 (x-3)^3 \\cdot \\cdot \\cdot (x-10)^{10}\\]  are removed from the number line, what remains is the union of $11$ disjoint open intervals. On how many of these intervals is $P(x)$ positive?"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/latex": [
       " $\\textbf{(A)}~3\\qquad\\textbf{(B)}~7\\qquad\\textbf{(C)}~6\\qquad\\textbf{(D)}~4\\qquad\\textbf{(E)}~5$ "
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parent = driver.find_element(By.CSS_SELECTOR, '.mw-parser-output')\n",
    "\n",
    "all_children = parent.find_elements(By.XPATH, './*')\n",
    "\n",
    "startpoint = parent.find_element(By.ID, 'Problem')\n",
    "\n",
    "endpoint = parent.find_element(By.ID, 'Solution_1')\n",
    "\n",
    "problem_elements = []\n",
    "capture = False\n",
    "\n",
    "\n",
    "\n",
    "# grab all the elements between problem word element, and answer element\n",
    "\n",
    "problem = ''\n",
    "for child in all_children:\n",
    "    if child.tag_name == 'h2' and not capture:\n",
    "        capture = True\n",
    "    elif child.tag_name == 'h2' and capture:\n",
    "        break\n",
    "    elif capture:\n",
    "        curr = ''\n",
    "        inner_html = child.get_attribute('innerHTML')\n",
    "        soup = BeautifulSoup(inner_html, 'html.parser')\n",
    "        for content in soup.descendants:\n",
    "            if content.name == 'img':\n",
    "                problem += ' ' + content.get('alt', '')\n",
    "                curr += ' ' + content.get('alt', '')\n",
    "            elif isinstance(content, str):\n",
    "                problem += ' ' + content.strip()\n",
    "                curr += ' ' + content.strip()\n",
    "        problem_elements.append(curr)\n",
    "        \n",
    "        \n",
    "answer = problem_elements[-1]\n",
    "problem = ''.join(problem_elements[:-1])\n",
    "display(Latex(problem))\n",
    "display(Latex(answer))\n",
    "        \n",
    "        \n",
    "\n",
    "# python only lets me make this a one liner \n",
    "# I think\n",
    "# answers = parent.find_element(By.XPATH, './/p[2]').find_element(By.CSS_SELECTOR, '.latex').get_attribute('alt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(all_children)\n",
    "# now we need to parse all the elements containing the problems\n",
    "# problem = ''\n",
    "# for element in problem_elements:\n",
    "#     for child in element.find_element(By.XPATH, './node()'):\n",
    "#         if child.tag_name == '':\n",
    "#             problem += ' ' + child.text.strip()\n",
    "#         elif child.tag_name == 'img':\n",
    "#             problem += ' ' + child.get_attribute('alt')\n",
    "\n",
    "# if not child.find_elements(By.TAG_NAME, 'img'):\n",
    "#             print(child.text)\n",
    "#         else:\n",
    "#             problem = ''\n",
    "#             for c in child.find_elements(By.XPATH, './/*'):\n",
    "#                 if c.tag_name == 'img':\n",
    "#                     problem += ' ' + c.get_attribute('alt')\n",
    "#                 else:\n",
    "#                     problem += ' ' + c.text\n",
    "#             print(problem)\n",
    "\n",
    "# repl = ['B', 'C', 'D', 'E']\n",
    "\n",
    "# for char in repl:\n",
    "#     answers = answers.replace(char, 'A')\n",
    "\n",
    "# answers = answers.replace('$', '').replace('\\qquad', '')\n",
    "\n",
    "# answers_arr = answers.split('\\\\textbf{(A) }')[1:]\n",
    "# print(answers_arr)\n",
    "\n",
    "# answer_map = {}\n",
    "\n",
    "# answer_map['A'] = answers_arr[0]\n",
    "# answer_map['B'] = answers_arr[1]\n",
    "# answer_map['C'] = answers_arr[2]\n",
    "# answer_map['D'] = answers_arr[3]\n",
    "# answer_map['E'] = answers_arr[4]\n",
    "\n",
    "# print(answer_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['Contest', 'Year', 'Number', 'Problem', 'Link', 'AnsA', 'AnsB', 'AnsC', 'AnsD', 'AnsE', 'Tags']\n",
    "contest, year, tags = 'AMC12B', 2023, ['geometry', 'number theory', 'combinatorics'] # just random example tags\n",
    "\n",
    "df = pd.DataFrame(columns=columns)\n",
    "\n",
    "for year in range(2002, 2023):\n",
    "    if year == 2021:\n",
    "        continue # this one has weird formatting, and the urls are different\n",
    "    # url = 'https://artofproblemsolving.com/wiki/index.php/' + str(year) + '_AMC_12A_Problems/Problem_'\n",
    "    for i in range(1, 26):\n",
    "        if (year == 2003 and i == 16):\n",
    "            continue # getting errors with 2003 12A #16, not sure why\n",
    "        number = str(i)\n",
    "        url = 'https://artofproblemsolving.com/wiki/index.php/' + str(year) + '_AMC_12A_Problems/Problem_' + number\n",
    "        driver.get(url)\n",
    "        print(url)\n",
    "        parent = driver.find_element(By.CSS_SELECTOR, '.mw-parser-output')\n",
    "        \n",
    "        all_children = parent.find_elements(By.XPATH, './*')\n",
    "\n",
    "        startpoint = parent.find_element(By.XPATH,  \"//*[contains(@id, 'Problem')]\")\n",
    "\n",
    "        endpoint = parent.find_element(By.XPATH, \"//*[contains(@id, 'Solution')]\")\n",
    "\n",
    "        problem_elements = []\n",
    "        capture = False\n",
    "\n",
    "\n",
    "\n",
    "        # grab all the elements between problem word element, and answer element\n",
    "        for child in all_children:\n",
    "            if child.tag_name == 'h2' and not capture:\n",
    "                capture = True\n",
    "            elif child.tag_name == 'h2' and capture:\n",
    "                break\n",
    "            elif capture:\n",
    "                curr = ''\n",
    "                inner_html = child.get_attribute('innerHTML')\n",
    "                soup = BeautifulSoup(inner_html, 'html.parser')\n",
    "                for content in soup.descendants:\n",
    "                    if content.name == 'img':\n",
    "                        curr += ' ' + content.get('alt', '')\n",
    "                    elif isinstance(content, str):\n",
    "                        curr += ' ' + content.strip()\n",
    "                problem_elements.append(curr)\n",
    "                \n",
    "                \n",
    "        answers = problem_elements[-1]\n",
    "        problem = ''.join(problem_elements[:-1])\n",
    "        # display(Latex(problem))\n",
    "        # print(answers)\n",
    "\n",
    "\n",
    "        repl = ['B', 'C', 'D', 'E']\n",
    "\n",
    "        for char in repl:\n",
    "            answers = answers.replace(char, 'A')\n",
    "\n",
    "        answers = answers.replace('$', '').replace('\\qquad', '').replace('\\\\textbf{(A) }', '\\\\textbf{(A)}').replace('\\\\textbf{(A)}', '\\\\text{(A)}')\n",
    "        answers_arr = answers.split('\\\\text{(A)}')[1:]\n",
    "\n",
    "        if not len(answers_arr) == 5:\n",
    "            print('skipping')\n",
    "            continue\n",
    "        if i == 16: print(problem)\n",
    "\n",
    "        df.loc[len(df)] = ['AMC12A', year, i, problem, url, answers_arr[0], answers_arr[1], answers_arr[2], answers_arr[3], answers_arr[4], tags]\n",
    "        print(str(year) + \" 12A \" + str(number))\n",
    "    \n",
    "    # url = 'https://artofproblemsolving.com/wiki/index.php/' + str(year) + '_AMC_12B_Problems/Problem_'\n",
    "    for i in range(1, 26):\n",
    "        number = str(i)\n",
    "        url = 'https://artofproblemsolving.com/wiki/index.php/' + str(year) + '_AMC_12B_Problems/Problem_' + number\n",
    "        driver.get(url)\n",
    "        print(url)\n",
    "        parent = driver.find_element(By.CSS_SELECTOR, '.mw-parser-output')\n",
    "        \n",
    "        all_children = parent.find_elements(By.XPATH, './*')\n",
    "\n",
    "        startpoint = parent.find_element(By.XPATH,  \"//*[contains(@id, 'Problem')]\")\n",
    "\n",
    "        endpoint = parent.find_element(By.XPATH, \"//*[contains(@id, 'Solution')]\")\n",
    "\n",
    "        problem_elements = []\n",
    "        capture = False\n",
    "\n",
    "\n",
    "\n",
    "        # grab all the elements between problem word element, and answer element\n",
    "        for child in all_children:\n",
    "            if child.tag_name == 'h2' and not capture:\n",
    "                capture = True\n",
    "            elif child.tag_name == 'h2' and capture:\n",
    "                break\n",
    "            elif capture:\n",
    "                curr = ''\n",
    "                inner_html = child.get_attribute('innerHTML')\n",
    "                soup = BeautifulSoup(inner_html, 'html.parser')\n",
    "                for content in soup.descendants:\n",
    "                    if content.name == 'img':\n",
    "                        curr += ' ' + content.get('alt', '')\n",
    "                    elif isinstance(content, str):\n",
    "                        curr += ' ' + content.strip()\n",
    "                problem_elements.append(curr)\n",
    "                \n",
    "                \n",
    "        answers = problem_elements[-1]\n",
    "        problem = ''.join(problem_elements[:-1])\n",
    "        # display(Latex(problem))\n",
    "        # print(answers)\n",
    "\n",
    "\n",
    "        repl = ['B', 'C', 'D', 'E']\n",
    "\n",
    "        for char in repl:\n",
    "            answers = answers.replace(char, 'A')\n",
    "\n",
    "        answers = answers.replace('$', '').replace('\\qquad', '').replace('\\\\textbf{(A) }', '\\\\textbf{(A)}').replace('\\\\textbf{(A)}', '\\\\text{(A)}')\n",
    "        answers_arr = answers.split('\\\\text{(A)}')[1:]\n",
    "\n",
    "        if not len(answers_arr) == 5:\n",
    "            print('skipping')\n",
    "            continue\n",
    "        if i == 16: print(problem)\n",
    "\n",
    "        df.loc[len(df)] = ['AMC12B', year, i, problem, url, answers_arr[0], answers_arr[1], answers_arr[2], answers_arr[3], answers_arr[4], tags]\n",
    "        print(str(year) + \" 12B \" + str(number))\n",
    "    \n",
    "\n",
    "print(df)\n",
    "df.to_csv('AMC12B_data', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scrape the solutions now\n",
    "\n",
    "# url = 'https://artofproblemsolving.com/wiki/index.php/2009_AMC_12A_Problems/Problem_9' # singular URL for now\n",
    "\n",
    "def get_soup(element):\n",
    "        inner_html = element.get_attribute('innerHTML')\n",
    "        soup = BeautifulSoup(inner_html, 'html.parser')\n",
    "        return soup\n",
    "\n",
    "def parse_solution(url):\n",
    "    driver.get(url)\n",
    "    print(url)\n",
    "    parent = driver.find_element(By.CSS_SELECTOR, '.mw-parser-output')\n",
    "\n",
    "    all_children = parent.find_elements(By.XPATH, './*')\n",
    "\n",
    "    # startpoint = parent.find_element(By.XPATH,  \"//*[contains(@id, 'Solution')]\")\n",
    "\n",
    "    # endpoint = parent.find_element(By.XPATH, \"//*[contains(@id, 'See_Also')]\")\n",
    "\n",
    "    problem_elements = []\n",
    "    capture = False\n",
    "\n",
    "    for child in all_children:\n",
    "        if child.tag_name == 'h2':\n",
    "            #     print(child.get_attribute('id'))\n",
    "            # if child.tag_name == 'h2' and 'Solution' in child.get_attribute('id'):\n",
    "            #     print('test1')\n",
    "            #     capture = True\n",
    "            # elif child.tag_name == 'h2' and 'See_Also' in child.get_attribute('id'):\n",
    "            #     print('test2')\n",
    "            #     break\n",
    "            soup = get_soup(child)\n",
    "            # I think if the tag is h2 then it should only have 1 descendant\n",
    "            desc = list(soup.descendants)\n",
    "            if hasattr(desc[0], 'text'):\n",
    "                content = desc[0].text.strip()\n",
    "                if 'Solution' in content:\n",
    "                    capture = True\n",
    "                elif content == 'See Also':\n",
    "                    break\n",
    "            \n",
    "        elif capture:       \n",
    "            curr = ''\n",
    "            soup = get_soup(child)\n",
    "            for content in soup.descendants:\n",
    "                if content.name == 'img':\n",
    "                    curr += ' ' + content.get('alt', '')\n",
    "                elif isinstance(content, str):\n",
    "                    curr += ' ' + content.strip()\n",
    "            problem_elements.append(curr)\n",
    "\n",
    "    solution = ''.join(problem_elements)\n",
    "    print(solution)\n",
    "    return solution\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('AMC12_data.csv')\n",
    "\n",
    "df['Solution'] = pd.NA\n",
    "\n",
    "def get_url_a(year, number):\n",
    "    return 'https://artofproblemsolving.com/wiki/index.php/' + str(year) + '_AMC_12A_Problems/Problem_' + str(number)\n",
    "\n",
    "def get_url_b(year, number):\n",
    "    return 'https://artofproblemsolving.com/wiki/index.php/' + str(year) + '_AMC_12B_Problems/Problem_' + str(number)\n",
    "\n",
    "\n",
    "# for year in range(2002, 2023):\n",
    "#     if year == 2021:\n",
    "#         continue\n",
    "#     for i in range(1, 26):\n",
    "#         matching_rows = (df['Year'] == year) & (df['Number'] == i) & (df['Contest'] == 'AMC12A')\n",
    "#         df.loc[matching_rows, 'Solution'] = parse_solution(get_url_a(year, i))\n",
    "\n",
    "#         matching_rows = (df['Year'] == year) & (df['Number'] == i) & (df['Contest'] == 'AMC12B')\n",
    "#         df.loc[matching_rows, 'Solution'] = parse_solution(get_url_b(year, i))\n",
    "\n",
    "def generate_url(contest, year, number):\n",
    "    return 'https://artofproblemsolving.com/wiki/index.php/' + str(year) + '_AMC_12' + str(contest)[-1] + '_Problems/Problem_' + str(number)\n",
    "for index, row in df.iterrows():\n",
    "    # Get the values from the 'Contest', 'Year', and 'Number' columns\n",
    "    contest = row['Contest']\n",
    "    year = row['Year']\n",
    "    number = row['Number']\n",
    "\n",
    "    # Generate the URL\n",
    "    url = generate_url(contest, year, number)\n",
    "\n",
    "    # Parse the solution from the URL\n",
    "    solution = parse_solution(url)\n",
    "\n",
    "    # Update the 'Solution' column with the returned value\n",
    "    df.at[index, 'Solution'] = solution\n",
    "    \n",
    "df.to_csv('AMC12_data.csv', index=False)\n",
    "print(df)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Your OpenAI API key\n",
    "openai_api_key = 'sk-proj-wNMCoN7x5cQv1F5DzCF0T3BlbkFJ5KQ7B3UUOEsV6NBvCfKb'\n",
    "\n",
    "# Endpoint URL for embeddings\n",
    "url = \"https://api.openai.com/v1/embeddings\"\n",
    "\n",
    "# Example Pandas Series\n",
    "texts_series = pd.read_csv('AMC12_data.csv')['Solution']\n",
    "\n",
    "# Convert the Pandas Series to a list\n",
    "texts = texts_series.tolist()\n",
    "\n",
    "# The model you want to use for embeddings, for example, 'text-embedding-ada-002'\n",
    "model = \"text-embedding-ada-002\"\n",
    "\n",
    "# Prepare the headers and data payload\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {openai_api_key}\",\n",
    "}\n",
    "\n",
    "data = {\n",
    "    \"model\": model,\n",
    "    \"input\": texts[:1],\n",
    "}\n",
    "\n",
    "# Convert the data dictionary to a JSON string\n",
    "json_data = json.dumps(data)\n",
    "\n",
    "# Send the POST request to the OpenAI API\n",
    "response = requests.post(url, headers=headers, data=json_data)\n",
    "print(response.text[:100])\n",
    "# Handle the response\n",
    "if response.status_code == 200:\n",
    "    response_json = response.json()\n",
    "    chunk_size = 10  # Print the first 10 items in the list, for example\n",
    "    print(\"Subset of JSON Data:\")\n",
    "    for item in response_json[:chunk_size]:\n",
    "        print(item)\n",
    "else:\n",
    "    print(\"Error:\", response.status_code)\n",
    "    print(\"Message:\", response.json())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
